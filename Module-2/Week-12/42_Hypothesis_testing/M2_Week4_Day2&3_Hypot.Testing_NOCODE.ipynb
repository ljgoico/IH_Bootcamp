{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Hypothesis-Testing-in-Python\" data-toc-modified-id=\"Hypothesis-Testing-in-Python-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Hypothesis Testing in Python</a></span></li><li><span><a href=\"#Two-Sample-Hypothesis-Tests-with-Scipy\" data-toc-modified-id=\"Two-Sample-Hypothesis-Tests-with-Scipy-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Two Sample Hypothesis Tests with Scipy</a></span><ul class=\"toc-item\"><li><span><a href=\"#Matched-Pairs\" data-toc-modified-id=\"Matched-Pairs-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Matched Pairs</a></span></li><li><span><a href=\"#Independent-Samples\" data-toc-modified-id=\"Independent-Samples-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Independent Samples</a></span></li></ul></li><li><span><a href=\"#More-Hypothesis-Testing-with-SciPy-and-Stats-Models\" data-toc-modified-id=\"More-Hypothesis-Testing-with-SciPy-and-Stats-Models-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>More Hypothesis Testing with SciPy and Stats Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#ANOVA-in-Python\" data-toc-modified-id=\"ANOVA-in-Python-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>ANOVA in Python</a></span></li><li><span><a href=\"#Linear-Regression\" data-toc-modified-id=\"Linear-Regression-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Linear Regression</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T09:38:12.736681Z",
     "start_time": "2019-07-13T09:38:12.733468Z"
    }
   },
   "source": [
    "# Hypothesis Testing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the Scipy library to perform hypothesis tests. The Scipy library has a function for one sample hypothesis tests called ttest_1samp. This test takes a dataset and a constant for comparison and returns the test statistic and the p value for a 2 sided test.\n",
    "\n",
    "Our test is a one-sided test so we will only look at the test statistic. In order to use the p-value we have to divide the p-value by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:29:30.642557Z",
     "start_time": "2019-08-05T06:29:30.113857Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:29:30.654930Z",
     "start_time": "2019-08-05T06:29:30.644798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-3.000831986203308, pvalue=0.0034069763375635686)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients = np.random.normal(5.1, 1.6, 100)\n",
    "ttest_1samp(patients, 5.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we generated random data with mean 5.1 and standard deviation 1.6 in order to simulate our patients. Our test statistic is close but not exactly the same since the mean of the sample is not exactly 5.1 like in the example but in fact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:29:30.661714Z",
     "start_time": "2019-08-05T06:29:30.657371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.240033260244129"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This explains the small discrepancy in the test statistic. However, the result is the same - we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Sample Hypothesis Tests with Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matched Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by looking at our dataset. The file blood_pressure.csv can be downloaded here.\n",
    "\n",
    "https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/data/module-2/blood_pressure.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:31:32.986537Z",
     "start_time": "2019-08-05T06:31:32.499501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136.713072</td>\n",
       "      <td>92.432965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134.735618</td>\n",
       "      <td>105.022643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127.529115</td>\n",
       "      <td>82.242766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144.527126</td>\n",
       "      <td>93.607172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124.214720</td>\n",
       "      <td>103.212223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       before       after\n",
       "0  136.713072   92.432965\n",
       "1  134.735618  105.022643\n",
       "2  127.529115   82.242766\n",
       "3  144.527126   93.607172\n",
       "4  124.214720  103.212223"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "blood_pressure = pd.read_csv('blood_pressure.csv')\n",
    "blood_pressure.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the scipy function ttest_rel. This function is used for hypothesis testing of dependent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:31:58.217647Z",
     "start_time": "2019-08-05T06:31:58.211498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-27.291841767560236, pvalue=7.303035069608042e-48)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "ttest_rel(blood_pressure.after, blood_pressure.before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our result is a very small p-value. This means that we will reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a matched pairs test is equivalent to a one sample test of the difference, we can also perform a one sample test and get the exact same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:32:24.420552Z",
     "start_time": "2019-08-05T06:32:24.413459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-27.291841767560236, pvalue=7.303035069608042e-48)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "ttest_1samp(blood_pressure.after-blood_pressure.before, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the p-value is identical since the tests are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scipy, this means that we will be setting equal_var=True in our function.\n",
    "\n",
    "The following is an example of a 2 sample hypothesis test with equal variance. We will load a sample dataset of transaction amounts from an e-commerce website. The dataset ab_test.csv can be downloaded here.\n",
    "\n",
    "https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/data/module-2/ab_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:34:30.808835Z",
     "start_time": "2019-08-05T06:34:30.797603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.27</td>\n",
       "      <td>13.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.08</td>\n",
       "      <td>21.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.74</td>\n",
       "      <td>9.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.70</td>\n",
       "      <td>5.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.00</td>\n",
       "      <td>12.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a      b\n",
       "0   0.27  13.61\n",
       "1   6.08  21.53\n",
       "2  13.74   9.23\n",
       "3   9.70   5.36\n",
       "4   7.00  12.90"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_test = pd.read_csv('ab_test.csv')\n",
    "ab_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the assumption that the variances of both populations are equal based on prior knowledge of the data. Now we will test that there is a significant difference between the website layouts with a 95% degree of confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:34:59.055242Z",
     "start_time": "2019-08-05T06:34:59.050024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.637533181209767, pvalue=0.009713140852447347)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "ttest_ind(ab_test.a, ab_test.b, equal_var=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our p-value is very small. This means that there is a significant difference between the two sample means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our A/B test data to perform a t-test that does not require the equal variance assumption:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:35:39.179780Z",
     "start_time": "2019-08-05T06:35:39.174627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.637533181209767, pvalue=0.009776243024828825)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(ab_test.a, ab_test.b, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the p-value slightly differs from the one we get with equal variances. However, since it is very small in this case as well, we will still reject the null hypothesis and conclude that there is a significant difference between the two sample means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Hypothesis Testing with SciPy and Stats Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of a dataset containing 8 observations of car loan interest rates from 6 different cities. We would like to show that there is a difference in the rates based on city. The dataset rate_by_city.csv can be obtained here.\n",
    "\n",
    "https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/data/module-2/rate_by_city.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:37:27.619796Z",
     "start_time": "2019-08-05T06:37:27.608013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rate  City\n",
       "0   13.75     1\n",
       "1   13.75     1\n",
       "2   13.50     1\n",
       "3   13.50     1\n",
       "4   13.00     1\n",
       "5   13.00     1\n",
       "6   13.00     1\n",
       "7   12.75     1\n",
       "8   12.50     1\n",
       "9   14.25     2\n",
       "10  13.00     2\n",
       "11  12.75     2\n",
       "12  12.50     2\n",
       "13  12.50     2\n",
       "14  12.40     2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "#let's load the dataset\n",
    "rate = pd.read_csv('rate_by_city.csv')\n",
    "rate.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:37:43.796503Z",
     "start_time": "2019-08-05T06:37:43.791895Z"
    }
   },
   "source": [
    "The dataset contains two columns - rate and city. To test our hypothesis, we need to either pass in multiple filtered subsets to our function or to pivot the dataset to have one column per city. We'll choose the second option. We'll start off by using the cumcount function to create a new index and then use the pivot function to create 6 city columns. We will then rename the columns to allow us to access them more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:37:48.337342Z",
     "start_time": "2019-08-05T06:37:48.315150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City_1</th>\n",
       "      <th>City_2</th>\n",
       "      <th>City_3</th>\n",
       "      <th>City_4</th>\n",
       "      <th>City_5</th>\n",
       "      <th>City_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.75</td>\n",
       "      <td>14.25</td>\n",
       "      <td>14.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>14.50</td>\n",
       "      <td>13.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.75</td>\n",
       "      <td>13.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>12.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.50</td>\n",
       "      <td>12.75</td>\n",
       "      <td>13.51</td>\n",
       "      <td>13.75</td>\n",
       "      <td>14.00</td>\n",
       "      <td>12.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.50</td>\n",
       "      <td>12.50</td>\n",
       "      <td>13.50</td>\n",
       "      <td>13.59</td>\n",
       "      <td>13.90</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.00</td>\n",
       "      <td>12.50</td>\n",
       "      <td>13.50</td>\n",
       "      <td>13.25</td>\n",
       "      <td>13.75</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City_1  City_2  City_3  City_4  City_5  City_6\n",
       "city_count                                                \n",
       "0            13.75   14.25   14.00   15.00   14.50   13.50\n",
       "1            13.75   13.00   14.00   14.00   14.00   12.25\n",
       "2            13.50   12.75   13.51   13.75   14.00   12.25\n",
       "3            13.50   12.50   13.50   13.59   13.90   12.00\n",
       "4            13.00   12.50   13.50   13.25   13.75   12.00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate['city_count'] = rate.groupby('City').cumcount()\n",
    "rate_pivot = rate.pivot(index='city_count', columns='City', values='Rate')\n",
    "rate_pivot.columns = ['City_'+str(x) for x in rate_pivot.columns.values]\n",
    "rate_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have successfully pivoted the data, we can perform the test. The f_oneway function requires us to specify each column that is passed into the function (rather than passing the entire dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:38:13.961383Z",
     "start_time": "2019-08-05T06:38:13.954945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=4.8293848737024, pvalue=0.001174551414504048)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_oneway(rate_pivot.City_1,rate_pivot.City_2,rate_pivot.City_3,rate_pivot.City_4,rate_pivot.City_5,rate_pivot.City_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is 0.001174. This value is very small, certainly smaller than 0.05. Therefore, we reject the null hypothesis and conclude that the rates differ by city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for generating an ANOVA in statsmodels is called anova_lm and it generates an ANOVA table. As a first step, we define a model and then generate the ANOVA table. In this case, we prefer not to pivot our data since the library will do it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:40:45.384012Z",
     "start_time": "2019-08-05T06:40:44.903471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(City)</th>\n",
       "      <td>10.945667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.829385</td>\n",
       "      <td>0.001175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>21.758133</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sum_sq    df         F    PR(>F)\n",
       "C(City)   10.945667   5.0  4.829385  0.001175\n",
       "Residual  21.758133  48.0       NaN       NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "model = ols('Rate ~ C(City)', data=rate).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table\n",
    "\n",
    "\n",
    "#sum_sqfloat64\n",
    "#Sum of squares for model terms.\n",
    "\n",
    "#dffloat64\n",
    "#Degrees of freedom for model terms.\n",
    "\n",
    "#Ffloat64\n",
    "#F statistic value for significance of adding model terms.\n",
    "\n",
    "#PR(>F)float64\n",
    "#P-value for significance of adding model terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we defined a model of rate and city. The pivoting is performed internally by using the C function. Our result is the same p-value and our conclusion to reject remains the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below, we will create a linear model that predicts MPG using acceleration in the auto-mpg dataset. Note that linregress only supports linear regression with one variable for x and one for y.\n",
    "\n",
    "The dataset auto-mpg.csv can be obtained here.\n",
    "\n",
    "https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/data/auto-mpg.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:42:32.028648Z",
     "start_time": "2019-08-05T06:42:32.011316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horse_power</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"chevrolet chevelle malibu\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"buick skylark 320\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"plymouth satellite\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"amc rebel sst\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"ford torino\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horse_power  weight  acceleration  \\\n",
       "0  18.0          8         307.0        130.0    3504          12.0   \n",
       "1  15.0          8         350.0        165.0    3693          11.5   \n",
       "2  18.0          8         318.0        150.0    3436          11.0   \n",
       "3  16.0          8         304.0        150.0    3433          12.0   \n",
       "4  17.0          8         302.0        140.0    3449          10.5   \n",
       "\n",
       "   model_year                       car_name  \n",
       "0          70  \\t\"chevrolet chevelle malibu\"  \n",
       "1          70          \\t\"buick skylark 320\"  \n",
       "2          70         \\t\"plymouth satellite\"  \n",
       "3          70              \\t\"amc rebel sst\"  \n",
       "4          70                \\t\"ford torino\"  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "auto = pd.read_csv('auto-mpg.csv')\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:42:41.906321Z",
     "start_time": "2019-08-05T06:42:41.900934Z"
    }
   },
   "outputs": [],
   "source": [
    "#Calculate a linear least-squares regression for two sets of measurements.\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = linregress(auto.acceleration, auto.mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:42:51.883262Z",
     "start_time": "2019-08-05T06:42:51.878690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1912045293502274,\n",
       " 4.9697930042539085,\n",
       " 0.4202889121016507,\n",
       " 1.8230915350787203e-18,\n",
       " 0.12923643283101396)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope, intercept, r_value, p_value, std_err\n",
    "\n",
    "#slopefloat\n",
    "#Slope of the regression line.\n",
    "\n",
    "#interceptfloat\n",
    "#Intercept of the regression line.\n",
    "\n",
    "#rvaluefloat\n",
    "#Correlation coefficient.\n",
    "\n",
    "#pvaluefloat\n",
    "#Two-sided p-value for a hypothesis test whose null hypothesis is that the slope is zero, using Wald Test with t-distribution of the test statistic.\n",
    "\n",
    "#stderrfloat\n",
    "#Standard error of the estimated gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that our regression equation is:\n",
    "\n",
    "mpg = 4.9698 + 1.1912 * acceleration\n",
    "\n",
    "The r squared is 0.1766 which is relatively small. This means that our model only captures 17% of the variation in the data.\n",
    "\n",
    "The p-value is very small, this means that the slope is significantly different from zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:43:08.724184Z",
     "start_time": "2019-08-05T06:43:08.695521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.177\n",
      "Model:                            OLS   Adj. R-squared:                  0.175\n",
      "Method:                 Least Squares   F-statistic:                     84.96\n",
      "Date:                Mon, 05 Aug 2019   Prob (F-statistic):           1.82e-18\n",
      "Time:                        08:43:08   Log-Likelihood:                -1343.9\n",
      "No. Observations:                 398   AIC:                             2692.\n",
      "Df Residuals:                     396   BIC:                             2700.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const            4.9698      2.043      2.432      0.015       0.953       8.987\n",
      "acceleration     1.1912      0.129      9.217      0.000       0.937       1.445\n",
      "==============================================================================\n",
      "Omnibus:                       17.459   Durbin-Watson:                   0.677\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.214\n",
      "Skew:                           0.497   Prob(JB):                     0.000111\n",
      "Kurtosis:                       2.670   Cond. No.                         91.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/Bismart_Raquel/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = sm.add_constant(auto.acceleration) # We must add the intercept using the add_constant function\n",
    "Y = auto.mpg\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "predictions = model.predict(X) \n",
    "\n",
    "print_model = model.summary()\n",
    "print(print_model)\n",
    "\n",
    "\n",
    "#El criterio de información de Akaike (AIC) es una medida de la calidad relativa de un modelo estadístico, para un conjunto dado de datos. Como tal, el AIC proporciona un medio para la selección del modelo.\n",
    "#AIC maneja un trade-off entre la bondad de ajuste del modelo y la complejidad del modelo.\n",
    "\n",
    "#The Bayesian information criterion (BIC) or Schwarz information criterion (also SIC, SBC, SBIC) is a criterion for model selection among a finite set of models; the model with the lowest BIC is preferred. It is based, in part, on the likelihood function and it is closely related to the Akaike information criterion (AIC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are not limited to only one predictor variable. Let's try this regression with more than one predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T06:43:40.636848Z",
     "start_time": "2019-08-05T06:43:40.615527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.700\n",
      "Model:                            OLS   Adj. R-squared:                  0.698\n",
      "Method:                 Least Squares   F-statistic:                     306.7\n",
      "Date:                Mon, 05 Aug 2019   Prob (F-statistic):          1.14e-102\n",
      "Time:                        08:43:40   Log-Likelihood:                -1142.9\n",
      "No. Observations:                 398   AIC:                             2294.\n",
      "Df Residuals:                     394   BIC:                             2310.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           42.3811      1.960     21.627      0.000      38.528      46.234\n",
      "cylinders       -0.4827      0.302     -1.599      0.111      -1.076       0.111\n",
      "weight          -0.0065      0.001    -11.342      0.000      -0.008      -0.005\n",
      "acceleration     0.2034      0.091      2.236      0.026       0.025       0.382\n",
      "==============================================================================\n",
      "Omnibus:                       34.469   Durbin-Watson:                   0.816\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               45.516\n",
      "Skew:                           0.654   Prob(JB):                     1.31e-10\n",
      "Kurtosis:                       4.016   Cond. No.                     2.82e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.82e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X = sm.add_constant(auto[['cylinders', 'weight', 'acceleration']]) # adding a constant\n",
    "Y = auto.mpg\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "predictions = model.predict(X) \n",
    "\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
